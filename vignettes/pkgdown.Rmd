---
title: "`cape` Vignette"
bibliography: bibliography.bib
output: 
  rmarkdown::html_vignette:
    fig_caption: yes
vignette: >
  %\VignetteIndexEntry{Introduction to the cape `R` package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo=FALSE}
library(cape)
```

# Introduction 

In epidemiological studies, an important quantity that needs to be estimated with great accuracy is the prevalence rate of a disease in order to learn more about central parameters such as case fatality rate and/or to plan and refine decisions about measures with regards to an epidemic or a pandemic. Traditionally, to measure the prevalence, a survey sample (of randomly chosen subjects from the population) is collected and the prevalence is estimated by the sample proportion. This process involves some financial and logistic efforts, which increase with the number of sampled participants, while at the same time, increasing the accuracy of the estimator. Having a sufficiently large sample is especially important when the (true) prevalence is very small, for example at the beginning of a new pandemic such as the one of the COVID-19. In this case, since the beginning of the outbreak, many measurements have been taken on the number of infected people, but only on the sub-population selected under some medical (and logistic) criteria. It is obvious that using these measurements as if they would be like a complete census, would lead to an underestimation of the prevalence. 

In  @guerrier2020prevalence, we propose to adequately use this information, together with data from a survey sample, in order to improve the accuracy of the prevalence estimation. In other terms, for a given (legal) statistical precision that might be required by authorities that finance a survey, the sample size can be a lot smaller if one adequately uses the information provided by the data collected in the sub-population. The possible misclassification  errors of the (medical) testing devices used to collect the data, are also taken into account. The misclassification  errors are actually induced by the sensitivity, i.e. the complement to the false positive rate, and by the specificity, i.e. the complement to the false negative rate, of the medical testing devices. The approach is a frequentist one, i.e. using cutoff values for the sensitivity and specificity, hence without the need to specify a (prior) distribution for these quantities. 


# Model

## Mathematical setup

Consider taking a (random) survey sample of $n$ participants in some population in order to estimate the prevalence $\pi$ of, for example, a given infectious disease. The framework also supposes that prior to the collection of the survey sample, measurement have been taken on a sub-population, not necessarily randomly chosen. Conditionally on this information, one can get  the prevalence computed as the number of positive cases (in the sub-population) relative to the (whole) population size, i.e. a prevalence parameter $\pi_0$ which is such that $\pi_0 \leq \pi$. While $\pi_0$ is known, it cannot be directly used as a proxy for $\pi$, but the information provided by $\pi_0$, can be used to improve the accuracy of the estimation of $\pi$.

More precisely, for each participant in the survey sample, the following information should be available:

\begin{equation}
    \begin{aligned}
         X_i& :=
         \left\{
	\begin{array}{ll}
		1  & \quad \mbox{if participant $i$ is positive,} \\
		0  & \quad \mbox{otherwise;}
	\end{array}
\right.\\
         V_i& := \left\{
	\begin{array}{ll}
		1  & \quad \mbox{if participant $i$ is positive and belongs to the sub-population,} \\
		0  & \quad \mbox{otherwise.}
	\end{array}
\right.
    \end{aligned}
    \label{eqn:bernoulli-rv}
\end{equation}

Note that $\Pr(X_i=1\vert V_i=1) = 1$ and $\Pr(X_i=0\vert V_i=1) = 0$. The objective is to provide an estimator for the unknown prevalence

\begin{equation}
        \pi := \Pr\left(X_i=1\right). 
        \label{eqn:true-pi}
\end{equation}

However, if we allow for possible misclassification error, the variables in \eqref{eqn:bernoulli-rv} are latent, and what is observed are the following variables

\begin{equation}
    \begin{aligned}
         Y_i& :=
         \left\{
	\begin{array}{ll}
		1  & \quad \mbox{if participant $i$ is tested positive in the survey sample,} \\
		0  & \quad \mbox{otherwise;}
	\end{array}
\right.\\
         W_i& := \left\{
	\begin{array}{ll}
		1  & \quad \mbox{if participant $i$ is tested positive and belongs to the sub-population,} \\
		0  & \quad \mbox{otherwise.}
	\end{array}
\right. 
    \end{aligned}
    \label{eqn:bernoulli-rv-obs}
\end{equation}

While $Y_i$ is the minimal information collected in the survey sample, $W_i$ is an additional information that could be obtained by asking the participants to provide it. It can be obtained while collecting the information on $Y_i$, or a posteriori using a followup procedure. In that case, it is not necessary to proceed to the followup for all sampled participants, but only for those with $Y_i=1$.

We also suppose that the (medical) testing devices have known sensitivity and specificity, or equivalently, False Positive (FP) rates  $\alpha = 1-\mbox{specificity}$  and False Negative (FN) rates $\beta = 1-\mbox{sensitivity}$, that might be different for the two populations. Therefore, we define the following quantities:

\begin{equation}
    \begin{aligned}
          \pi_0 & := \Pr(W_i=1) && \\
    \alpha_0& := \Pr(W_i=1\vert V_i=0) & \quad \quad \alpha& := \Pr(Y_i=1\vert X_i=0) \\
    \beta_0& := \Pr(W_i=0\vert V_i=1) & \quad \quad \beta& := \Pr(Y_i=0\vert X_i=1).
    \end{aligned}
    \label{eqn:missclasserrors}
\end{equation}

For proper modelling, we assume that $\alpha+\beta<1$ and $\alpha_0+\beta_0<1$ [see @guerrier2020prevalence]. From the above definitions, we can deduce

\begin{equation*}
    \pi^*_0=\Pr(V_i=1)=\frac{1}{\Delta_0}(\pi_0-\alpha_0) 
\end{equation*}

with $\Delta_0=1-(\alpha_0+\beta_0)$. In the figure below, we present the probability tree associated to the variables involved in this study:

<center>
<img src="prob.png" alt=" " width="600"/>
</center>

From these variables we deduce the following random variables that are necessary for estimation and inference:

\begin{eqnarray}
R_1:=\sum_{i=1}^nY_iW_i \;\;\; \mbox{and} \;\;\;
R_3:= \sum_{i=1}^nY_i(1-W_i) 
\label{eqn:R-R4} 
\end{eqnarray}

with:

- $R_1$: the number of participants in the survey sample that were tested positive with both (medical) testing devices (and are, thus, members of the sub-population);
- $R_3$ is the number of participants in the survey sample that are tested positive only with the second  testing device.

If easily available, on can add the following information, that might increase estimation and inference accuracy for survey sample sizes smaller than $n=1,500$:

\begin{equation*}
    R_2:=\sum_{i=1}^n(1-Y_i)W_i
\end{equation*}

so that $R_0:= \sum_{i=1}^nW_i=R_1+R_2$, with

- $R_0$: the number of participants in the survey sample that were tested positive in the sub-population;
- $R_2$: the number of participants in the survey sample that are tested positive only with the first  testing device (and are, thus,  members of the sub-population).
   
The respective distributions of $R_1,R_2,R_3$ are binomial distributions with success probabilities given below in the next section.


## Simulating data

Data can be simulated using the function `sim_Rs()` as follows:

```{r}
# Load cape package
library(cape)

# Measurement error
alpha = alpha0 = 0.01
beta = beta0 = 0.02

# Simulation "seed"
seed = 18

# True prevalence
theta = 4/100

# Prevalence in sub-population
pi0 = 2/100

# Sample size
n = 1500

# Simulation data
R = sim_Rs(theta = theta, pi0 = pi0, n = n, alpha0 = alpha0,
           alpha = alpha, beta0 = beta0, beta = beta, seed = seed)

# Print results
R
```

# Estimators

The success probabilities associated to $R_j,j=1,2,3$ are functions of the (true) prevalence $\pi$, and are given  by 

\begin{eqnarray}
    \begin{aligned}
    \tau_1(\pi) &:=  \Pr(W_i=1, Y_i=1) =\pi\Delta\alpha_0+\pi_0^*\Delta_0(1-\beta)+\alpha\alpha_0   \\
    \tau_2(\pi) &:=  \Pr(W_i=1,Y_i=0) = -\pi\Delta\alpha_0+\pi_0^*\Delta_0\beta+(1-\alpha)\alpha_0  \\
    \tau_3(\pi) &:=  \Pr(W_i=0,Y_i=1) = \pi\Delta(1-\alpha_0)-\pi_0^*\Delta_0(1-\beta)+\alpha(1-\alpha_0)  \\
    \tau_4(\pi) &:=  \Pr(W_i=0,Y_i=0) = -\pi\Delta(1-\alpha_0)-\pi_0^*\Delta_0\beta+(1-\alpha)(1-\alpha_0),
    \end{aligned}
    \label{eqn:tau-pi}
\end{eqnarray}

where $\Delta :=1-(\alpha+\beta)$. A likelihood function can be built based on the multinomial distribution (with categories $R_1,R_2,R_3,R_4$, with $R_4=1-R_1-R_2-R_3$) to obtain the conditional Maximum Likelihood Estimator (MLE) for $\pi$ [see @guerrier2020prevalence]. The MLE has a closed form expressions if $\alpha_0=0$. If the information provided by $R_2$ is not available, the likelihood function is marginalized out on $R_2$ and one can still obtain an MLE for $\pi$. Alternatively, the package also contains a Method of Moments Estimator (MME) based on $R_3$ (with expectation $\tau_3(\pi)$), which is closed form for any $\alpha_0,\alpha,\beta_0,\beta$.

The confidence intervals for the conditional MLE and the marginal MLE can be computed using asymptotic theory. They provide good coverage, with small interval length for survey sample sizes from $n=1,000$ [see @guerrier2020prevalence]. For the MME, since its finite sample distribution is known through $R_3\sim\mathcal{B}(n,\tau_3(\pi))$, exact confidence bounds can be computed using, for example, the (fiducial) Clopperâ€“Pearson (CP) approach method, see @ClPe34, @fisher35 and @brown2001. In the package are implemented, the CP method based on $R_3$, and the asymptotic theory method for the conditional and marginal MLE (i.e. $R_2$ known or not). An extensive simulation study is provided in @guerrier2020prevalence that compares coverage probabilities with the different approaches.

To obtain these estimators, one can use the functions `conditional_mle()`, `marginal_mle()` and `moment_estimator()`. Indeed, the conditional MLE can be estimated as follows on the previously simulated data:

```{r}
fit_cmle = conditional_mle(R1 = R$R1, R2 = R$R2, R3 = R$R3, R4 = R$R4, n = R$n, pi0 = R$pi0,
                           alpha0 = R$alpha0, alpha = R$alpha, 
                           beta0 = R$beta0, beta = R$beta)
fit_cmle
```

Note that the conditional MLE is based on $R_1$, $R_2$, $R_3$ and $R_4$ while the marginal MLE is based on only $R_1$ and $R_3$. This estimator can be obtained as follows:

```{r}
fit_mmle = marginal_mle(R1 = R$R1, R3 = R$R3, n = R$n, pi0 = R$pi0,
                        alpha0 = R$alpha0, alpha = R$alpha, 
                        beta0 = R$beta0, beta = R$beta)
fit_mmle
```

Moreover, the moment estimator, which is simply based on $R_3$, can be computed as follows:

```{r}
fit_mme = moment_estimator(R3 = R$R3, n = R$n, pi0 = R$pi0,
                           alpha0 = R$alpha0, alpha = R$alpha, 
                           beta0 = R$beta0, beta = R$beta)
fit_mme
```

It can be observed that the function `moment_estimator()` provides both asymtoptic and CP confidence intervals. Finally for comparison purposes, `cape` package also contains the MLE based on the sample survey, i.e. the sample average estimator, which can be obtained as follows:

```{r}
fit_smle = survey_mle(R = R$R, n = R$n, alpha = R$alpha, beta = R$beta)
fit_smle
```

# References

